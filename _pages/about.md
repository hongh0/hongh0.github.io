---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>


I am currently an undergraduate student at Shandong University (SDU) majoring in Computer Science and Technology, and will be graduating in June of this year. Previously, I received my B.S. in Computer Science and Technology from Shandong University in 2024 and my B.S. with honors from Shandong University.

My research interests include computer vision, generative artificial intelligence, and machine learning.

<!-- I have published more than 100 papers at the top international AI conferences with total <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'>google scholar citations <strong><span id='total_cit'>260000+</span></strong></a> (You can also use google scholar badge <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>). -->


# üî• News
- *2024.06*: &nbsp;üéâüéâ Awarded BS Honors Student from Shandong University. 
- *2024.01*: &nbsp;üéâüéâ Awarded Outstanding Graduates from Shandong University. 

# üìù Publications 
\* indicates equal contribution

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ArXiv</div><img src='images/Style-Consistent.pdf' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

## Style-Consistent 3D Indoor Scene Synthesis with Decoupled Objects

Yunfan Zhang, **Hong Huang**, Zhiwei Xiong, Zhiqi Shen, Guosheng Lin, Hao Wang, Chan Hua Vun

[**Paper**](https://arxiv.org/abs/2401.13203) 
<!-- [**Project**](https://dreamscene360.github.io/)|
[**Code**](https://dreamscene360.github.io/) -->
<strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- We introduce a unique pipeline designed for synthesis 3D indoor scenes. The core strength of our pipeline lies in its ability to generate 3D scenes that are not only visually impressive but also exhibit features like photorealism, multi-view consistency, and diversity.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">BSPC</div><img src='images/FLD_ACA.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

## A fatty liver diseases classification network based on adaptive coordination attention with label smoothing

**Hong Huang**, Yong Liu, Qiuju Xiong, Yuanxiu Xing, Honglei Du

[**Paper**](https://www.sciencedirect.com/science/article/abs/pii/S1746809423007000) 
<!-- [**Project**](https://dreamscene360.github.io/)|
[**Code**](https://dreamscene360.github.io/) -->
<strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- The proposed approach achieves end-to-end automatic classification by solely utilizing images as input, thereby avoiding the decoupling of feature extraction.
</div>
</div>

<!-- <div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2016</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)

**Kaiming He**, Xiangyu Zhang, Shaoqing Ren, Jian Sun

[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
</div>
</div>

- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020** -->

# üéñ Honors and Awards
- *2024.06* BS Honors Student, Shandong University. 
- *2024.01* Outstanding Graduate, Shandong University. 

<!-- # üìñ Educations
- *2019.06 - 2022.04 (now)*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2015.09 - 2019.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  -->

<!-- # üí¨ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/) -->

# üíª Experience
- *2023.11 - 2024.03*, Research Intern, Advisor: [Hao Wang](https://wanghao.tech/), Hong Kong University of Science and Technology (Guangzhou).